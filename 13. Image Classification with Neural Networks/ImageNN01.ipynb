{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1XqvZFrCt2RWKDoe-FkeIvoh8Ln9o9TwS","authorship_tag":"ABX9TyM3jKGfyG/OCsR+JNCFar5o"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<center>\n","<img src=\"https://i.ibb.co/ZVRt2f7/logo.png\" alt=\"logo\" border=\"0\" width=800>\n"],"metadata":{"id":"bB2VgAZdSyGU"}},{"cell_type":"markdown","source":["---\n","## 01. An Image Classification Neural Network\n","\n","\n","Eduard Larra√±aga (ealarranaga@unal.edu.co)\n","\n","---"],"metadata":{"id":"1sJXZQswS3Vd"}},{"cell_type":"markdown","source":["### Abstract\n","\n","In this notebook we will train a neural network to classify images.\n","\n","---"],"metadata":{"id":"tCOJ84FdS9ZM"}},{"cell_type":"markdown","source":["---\n","\n","## The Dataset\n","\n","We will use two sets of synthetic images to train and to test a neural network. The training set includes 5000 synthetic images with a size of 28pixels by 28 pixels, showing a black background and a random number of 'stars' and also includes a set of targets with the number of stars in each image. The test set includes 1000 of images with the corresponding targets. \n"],"metadata":{"id":"sLUz0CMlBOXi"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","\n","train_images = np.load(\"/content/drive/MyDrive/Colab Notebooks/Neural Networks/02. Image Classification NN/star_data/star_image_train.npy\")\n","train_labels = np.load(\"/content/drive/MyDrive/Colab Notebooks/Neural Networks/02. Image Classification NN/star_data/star_label_train.npy\")\n","\n","test_images = np.load(\"/content/drive/MyDrive/Colab Notebooks/Neural Networks/02. Image Classification NN/star_data/star_image_test.npy\")\n","test_labels = np.load(\"/content/drive/MyDrive/Colab Notebooks/Neural Networks/02. Image Classification NN/star_data/star_label_test.npy\")"],"metadata":{"id":"VNQA3G7Vu4tM","executionInfo":{"status":"ok","timestamp":1668638699685,"user_tz":300,"elapsed":10168,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["print(train_images.shape)\n","print(train_labels.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RGq4-YK3gebC","executionInfo":{"status":"ok","timestamp":1668638706550,"user_tz":300,"elapsed":200,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"622162aa-67b0-46fe-9f1b-635cddc11e8c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["(5000, 28, 28)\n","(5000,)\n"]}]},{"cell_type":"code","source":["print(test_images.shape)\n","print(test_labels.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OdBlDmVLKsFs","executionInfo":{"status":"ok","timestamp":1668458759982,"user_tz":300,"elapsed":279,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"889d7889-ac23-418f-f24f-57eaa48cf946"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(1000, 28, 28)\n","(1000,)\n"]}]},{"cell_type":"markdown","source":["These images are already 'normalized', i.e. the entries in the array are numbers in the range [0,1],"],"metadata":{"id":"oRnoE127LAGo"}},{"cell_type":"code","source":["train_images[413]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1D3YqTN6LN22","executionInfo":{"status":"ok","timestamp":1668638731643,"user_tz":300,"elapsed":238,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"94002f01-b855-45b7-dd87-41d135e6d42b"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.18002858, 0.34436902, 0.21825997,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.39468033, 1.        , 0.13583779,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.15602839, 0.24055161, 0.43913993,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.18535556, 0.01377525, 0.1952437 ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.27935938, 1.        , 0.49638377,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.14767573, 0.06532711, 0.07341733,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        ]])"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["We can visualize some of the images in the trining set,"],"metadata":{"id":"ZBxviEp8Kv_5"}},{"cell_type":"code","source":["fig, ax = plt.subplots(1,7, figsize=(15,7))\n","\n","for i in range(7):    \n","    ax[i].imshow(train_images[i+5], cmap='gray')\n","    ax[i].set_xticks([])\n","    ax[i].set_yticks([])\n","    ax[i].set_xlabel(f'Number of stars : {train_labels[i+5]:.0f}')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":168},"id":"Sjk_L8BGKjCU","executionInfo":{"status":"ok","timestamp":1668458813667,"user_tz":300,"elapsed":642,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"c3e549ba-25f1-4919-da40-6a91302a59b1"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1080x504 with 7 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["def showImage(x,y,item):\n","  plt.figure()\n","  plt.imshow(x[item], cmap='gray')\n","  plt.xticks([])\n","  plt.yticks([])\n","  plt.xlabel(f'Number of stars : {y[item]:.0f}')\n","  plt.show()\n","\n","\n","showImage(train_images, train_labels, 2557)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"id":"X8HF6JXTH7F8","executionInfo":{"status":"ok","timestamp":1668458863958,"user_tz":300,"elapsed":275,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"78919723-53e5-4bc6-f54b-681be1658150"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAOsAAAD1CAYAAACx1gI+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAIVUlEQVR4nO3cb2hddx3H8c+naV3K3BbcVqgoa5TJHlhWNA4LVVuZsgdFxtiEIQx0Nk7QiTpBVGR5tjELe7xVWoU9GQpWtEwfuD8+iV2d2X+tda6jZdiJXbUZaZvk64NziteQe5Obtks/y/sFl9x7f+d3zrl3vHPOvSedq0oALn6rlnsHACwOsQIhiBUIQaxACGIFQqzuZ2HbfHUMXGBV5fme58gKhCBWIASxAiGIFQhBrEAIYgVCECsQgliBEMQKhCBWIASxAiGIFQhBrEAIYgVCECsQgliBEMQKhCBWIASxAiGIFQhBrEAIYgVCECsQgliBEMQKhCBWIASxAiGIFQhBrEAIYgVCECsQgliBEMQKhCBWIASxAiGIFQhBrEAIYgVCrF7uHQASjYyMdB07ePBgz7nDw8NLmsuRFQhBrEAIYgVCECsQgliBEMQKhCBWIATXWYElmJ6e7jp24sSJnnN37NjRdezo0aNdxziyAiGIFQhBrEAIYgVCECsQgliBEH1duhkaGtK2bdu6jg8MDPScf+TIka5j4+Pj/ewKsKwGBwe7jm3YsKHn3I0bN3YdO3PmTNcxjqxACGIFQhArEIJYgRDECoQgViAEsQIh+rrOOjs7q6mpqa7j+/bt6zl/8+bN/WwOuGidy98FHD58eEnzOLICIYgVCEGsQAhiBUIQKxCCWIEQxAqE6Os668zMjI4fP951fPv27T3nT0xM9LM5YNmMjo72HO/1b7fXrVvXc+7Y2NiS9okjKxCCWIEQxAqEIFYgBLECIYgVCEGsQIi+rrNOTk7y//fFinD69Ome47t37+46tmbNmvO9O5I4sgIxiBUIQaxACGIFQhArEIJYgRDECoRwVS1+YXvxCwPBtmzZ0nN8dna269ixY8d6zj106FDP8aryfM9zZAVCECsQgliBEMQKhCBWIASxAiG4dANcZLh0A4QjViAEsQIhiBUIQaxACGIFQhArEIJYgRDECoQgViAEsQIhiBUIQaxACGIFQhArEIJYgRDECoQgViAEsQIhiBUIQaxACGIFQhArEIJYgRDECoQgViAEsQIhiBUIQaxACGIFQhArEIJYgRDECoQgViAEsQIhiBUIQaxACGIFQhArEIJYgRDECoQgViAEsQIhiBUIQaxACGIFQhArEIJYgRDECoQgViAEsQIhiBUIQaxACGIFQhArEIJYgRDECoQgViAEsQIhiBUIQaxACGIFQhArEIJYgRDECoQgViAEsQIhiBUIQaxACGIFQhArEIJYgRDECoQgViAEsQIhiBUIQaxACGIFQhArEIJYgRDECoQgViAEsQIhiBUIQaxACGIFQhArEIJYgRDECoQgViAEsQIhiBUIQaxACGIFQhArEIJYgRDECoQgViAEsQIhiBUIQaxACGIFQhArEIJYgRDECoQgViAEsQIhiBUIQaxACGIFQhArEIJYgRDECoQgViAEsQIhiBUIQaxACGIFQhArEIJYgRDECoQgViAEsQIhiBUIsbrP5f8p6fCF2BEAkqRrug24qt7OHQGwRJwGAyGIFQhBrEAIYl2A7bK9s+PxPbbvPU/r3mP71vOxrgW2c5vtl20/vsjlv3eh92nO9gZt77f9rO0XbY+9ndtPQawLOyXpFttXLfeOdLLdzzf5d0raUVXbFrl837HaHuh3TodTkj5dVddL2iTpJtsfP4f1vSMR68KmJT0k6ZtzB+YeGW2fbH9utf2k7b22X7F9n+0vtEeP521/sGM1N9o+YPug7e3t/AHbD9h+2vZztr/Ssd7f2/6lpJfm2Z/b2/W/YPv+9rkfStoi6ce2H5iz/HrbT9meaOd8wvZ9kta2zz3SLvcL239sj3qjna/X9k7bz0ra3L7Ol9p9/tFi3+BqnGwfrmlvXKaYq6q49bhJOinpckmvSrpC0j2S7m3H9ki6tXPZ9udWSW9KWi/pEklHJY21Y9+Q9GDH/MfU/NK8VtIRSYOSRiX9oF3mEkkHJA23652UNDzPfr5X0muSrlZz/fx3km5ux56QNDLPnG9L+n57f0DSZZ2vo2O597Q/10p6QdKV7eOS9Pn2/pWS/qL/XQ4cmmd7I5J2dXmfByRNtO/3/cv93/1ivHFkXYSq+rekn0q6u49pT1fV61V1StLfJP22ff55SRs6lnu0qmar6q+SXpF0naTPSrrD9oSkP6gJ4dp2+f1V9fd5tvcxSU9U1RtVNS3pEUmfXGgfJX2x/Qy+sar+02W5u9uj57ik93fsy4ykn7f3T0iaUnMEv0XSW3NXUlUHqurL822gqmaqapOk90m6wfaHF9j3FYdYF+9BNZ/9Lu14blrte2h7laR3dYyd6rg/2/F4Vv//l2NzT/dKkiV9vao2tbfhqjob++Q5vYrODVU9pSboo5L22L5j7jK2t0q6UdLmaj5T/knN0V+Spqpqpl3XtKQbJP1M0nY1ZwxL2ac3JT0u6aalzH8nI9ZFqqp/SXpUTbBnvSrpo+39z6n5rNWv22yvaj/HfkDNqeRvJH3V9hpJsv0h25f2Womk/ZI+Zfuq9sue2yU92WuC7Wsk/aOqHpa0S9JH2qEzZ7et5tT/eFW9Zfs6SfN+8WP73ZKuqKp9aj7fX7/A/nbOvdr2UHt/raTPSPrzYuevFP3+bfBKt1PS1zoePyxpb3uK+JiWdtR7TU1ol0u6q6qmbO9Sc6r8jG1LekPSzb1WUlWv2/6umqOSJf26qvYusO2tkr5j+4yaz4pnj6wPSXrO9jOSviTpLtsvq/lFMt5lXZepeS8G2+1/a+4Ctkfa1zj3VHi9pJ+0v2RWqflo8KsF9n3F4W+DgRCcBgMhiBUIQaxACGIFQhArEIJYgRDECoT4L6luiC4L5mb7AAAAAElFTkSuQmCC\n"},"metadata":{}}]},{"cell_type":"markdown","source":["## The Classification Neural Network\n","\n","We want to train a neural network model that reads the data and classify these images according to the number of stars (targets). Therefore we need to declare the following:\n","\n","- An input layer that reads the data in the image. This will be a 'Flatten' layer (it will take the image of size 28 by 28 and will convert it into a flat array with 784 entries). Therefore, we need 784 neurons in this layer.\n","\n","- We will use 2 hidden dense layer with 50 neurons and a ReLU activation (ReLU will ignore negative values)\n","\n","- Finally we will incorporate an output dense layer with 6 neurons (because the number of stars in the set goes from 0 to 5) and a 'softmax' activation function.\n","\n","- The model will be a 'Sequential' neural network."],"metadata":{"id":"_d5apPDlLYvg"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","\n","# input layer: Type Flatten. The input is an image of 28x28 pixels with 1 channel\n","inputlyr = tf.keras.layers.Flatten(input_shape=(28,28,1))\n","\n","# hidden layers with 50 neurons and relu\n","hdnlyr01 = tf.keras.layers.Dense(units=50, activation=tf.nn.relu)\n","hdnlyr02 = tf.keras.layers.Dense(units=50, activation=tf.nn.relu)\n","\n","# output layer\n","outlyr = tf.keras.layers.Dense(units=6, activation=tf.nn.softmax)\n","\n","\n","model = tf.keras.Sequential([inputlyr, hdnlyr01, hdnlyr02, outlyr])\n"],"metadata":{"id":"4iRc3G6PPlre"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In order to compile the neural network we will include the [ADAM](https://keras.io/api/optimizers/adam/) optimizer, the [SparseCategoricalCrossentropy](https://keras.io/api/losses/probabilistic_losses/#categoricalcrossentropy-class) loss function and the [accuracy](https://keras.io/api/metrics/accuracy_metrics/#accuracy-class) metric."],"metadata":{"id":"fpfPb6iQMrDL"}},{"cell_type":"code","source":["model.compile(\n","    optimizer = tf.keras.optimizers.Adam(),\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n","    metrics=['accuracy']\n",")"],"metadata":{"id":"5hIear72ytiq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###¬†The CategoricalCrossentropy and the SparseCategoricalCrossentropy loss functions \n","\n","The [CategoricalCrossentropy](https://keras.io/api/losses/probabilistic_losses/#categoricalcrossentropy-class) and the [SparseCategoricalCrossentropy](https://keras.io/api/losses/probabilistic_losses/#sparsecategoricalcrossentropy-class) loss functions are used to measure the  cost of a classification model.\n","\n","In order to use these function, the algorithm may use and encoding to represent the targets. For example, if one has some categorical targets, they are first represented as integer values:\n","\n","- TargetA ---> 0 \n","- TargetB ---> 1\n","- TargetC ---> 2\n","- TargetD ---> 3\n","...\n","\n","Under this encoding, we can use the 'sparsecategorical_crossentropy' function which is defined as\n","\n","\\begin{equation}\n","J(w) = -\\sum_{i=1}^N y_i\\log (y_i^p) \n","\\end{equation}\n","\n","\n","\n","Another representation is obtained by using the **one-hot encoding**, which is based on the use of binary vectors. In this case each integer assigned to the categorical targets is represented as a binary vector, that is all zero values except the index of the integer which is marked with a 1. For example:\n","\n","- TargetA ---> 0  ---> [1 0 0 0]\n","- TargetB ---> 1  ---> [0 1 0 0]\n","- TargetC ---> 2  ---> [0 0 1 0]\n","- TargetD ---> 3  ---> [0 0 0 1]\n","...\n","\n","Under this encoding, we can use the 'categorical_crossentropy' function which is defined as before\n","\n","\\begin{equation}\n","J(w) = -\\sum_{i=1}^N y_i \\log (y_i^p) \n","\\end{equation}\n"],"metadata":{"id":"JG8S5WKV_hun"}},{"cell_type":"markdown","source":["\n","\n","### Metrics\n","\n","A metric is a function that is used to judge the performance of the model.\n","\n","Metric functions are similar to loss functions, except that the results from evaluating a metric are not used when training the model (In fact, one can use any loss function as a metric).\n","\n","Keras includes many [metrics](https://keras.io/api/metrics/):\n","\n","**Accuracy metrics**\n","- Accuracy class\n","- BinaryAccuracy class\n","- CategoricalAccuracy class\n","- SparseCategoricalAccuracy class\n","- TopKCategoricalAccuracy class\n","- SparseTopKCategoricalAccuracy class\n","\n","**Probabilistic metrics**\n","- BinaryCrossentropy class\n","- CategoricalCrossentropy class\n","- SparseCategoricalCrossentropy class\n","- KLDivergence class\n","- Poisson class\n","\n","**Regression metrics**\n","- MeanSquaredError class\n","- RootMeanSquaredError class\n","- MeanAbsoluteError class\n","- MeanAbsolutePercentageError class\n","- MeanSquaredLogarithmicError class\n","- CosineSimilarity class\n","- LogCoshError class\n","\n","**Classification metrics based on True/False positives & negatives**\n","- AUC class\n","- Precision class\n","- Recall class\n","- TruePositives class\n","- TrueNegatives class\n","- FalsePositives class\n","- FalseNegatives class\n","- PrecisionAtRecall class\n","- SensitivityAtSpecificity class\n","- SpecificityAtSensitivity class\n","- Image segmentation metrics\n","- MeanIoU class\n","- Hinge metrics for \"maximum-margin\" classification\n","- Hinge class\n","- SquaredHinge class\n","- CategoricalHinge class"],"metadata":{"id":"uw1eiKCK-9yW"}},{"cell_type":"code","source":["# print model summary before training\n","model.summary()"],"metadata":{"id":"DqB3pBWycASs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668458898186,"user_tz":300,"elapsed":207,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"829cab96-3ccf-4da8-f345-461b0ef0f9c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten (Flatten)           (None, 784)               0         \n","                                                                 \n"," dense (Dense)               (None, 50)                39250     \n","                                                                 \n"," dense_1 (Dense)             (None, 50)                2550      \n","                                                                 \n"," dense_2 (Dense)             (None, 6)                 306       \n","                                                                 \n","=================================================================\n","Total params: 42,106\n","Trainable params: 42,106\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["Now we will train the model using the train-sets and 5 epochs."],"metadata":{"id":"ZfwiwAyvM7_s"}},{"cell_type":"code","source":["history = model.fit(train_images, train_labels, epochs=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wKhmMuV44Ugo","executionInfo":{"status":"ok","timestamp":1668458915097,"user_tz":300,"elapsed":3279,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"694fb4a0-0403-4027-cb12-5839e83e3071"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","157/157 [==============================] - 1s 2ms/step - loss: 1.5401 - accuracy: 0.2516\n","Epoch 2/5\n","157/157 [==============================] - 0s 2ms/step - loss: 0.8466 - accuracy: 0.7658\n","Epoch 3/5\n","157/157 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8914\n","Epoch 4/5\n","157/157 [==============================] - 0s 2ms/step - loss: 0.2780 - accuracy: 0.9272\n","Epoch 5/5\n","157/157 [==============================] - 0s 2ms/step - loss: 0.2042 - accuracy: 0.9468\n"]}]},{"cell_type":"markdown","source":["Note that the training gives an accuracy (with the training set) of 0.9430 and a final cost function fo 0.2283"],"metadata":{"id":"eikQyAevamKP"}},{"cell_type":"markdown","source":["---\n","## Testing the Model\n","\n","Now we will use the test subsets to probe the model. Using the '.evaluate()' method, we obtain the accuracy of the model (using the metric defined above),"],"metadata":{"id":"ydSWhoQxgqx_"}},{"cell_type":"code","source":["test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n","\n","print('\\nTest accuracy:', test_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fWufSHITNZKs","executionInfo":{"status":"ok","timestamp":1668458933188,"user_tz":300,"elapsed":228,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"c062f7ab-398c-4e5b-97d9-5ccfae8bae44"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 - 0s - loss: 0.3447 - accuracy: 0.8540 - 142ms/epoch - 4ms/step\n","\n","Test accuracy: 0.8539999723434448\n"]}]},{"cell_type":"markdown","source":["Note that the trained model have an accuracy of 0.85 on the test set.\n","\n","Using the '.predict()' method we will obtain the predictions for the test set,"],"metadata":{"id":"wXK9nA5WhPpZ"}},{"cell_type":"code","source":["predictions= model.predict(test_images)"],"metadata":{"id":"GskOfRL7vuaE","executionInfo":{"status":"ok","timestamp":1668458947317,"user_tz":300,"elapsed":211,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8082f03a-0016-43a5-8b19-06ff5e90ea6b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["32/32 [==============================] - 0s 931us/step\n"]}]},{"cell_type":"markdown","source":["The result for a particular sample is a collection of probabilities associated with each of the possible targets (number of stars from 0 to 5),"],"metadata":{"id":"os5tZ7M7hwAN"}},{"cell_type":"code","source":["predictions[18]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nLs6ezc9h_Fj","executionInfo":{"status":"ok","timestamp":1668458949863,"user_tz":300,"elapsed":192,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"447619ba-70e8-4e60-98b3-6dd37503a518"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([3.1761597e-03, 9.1313159e-01, 8.3340317e-02, 3.5128411e-04,\n","       8.0465992e-07, 5.5277494e-10], dtype=float32)"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["Since we use the activation function 'softmax' in the output layer, the sum of all the probabilities for a single sample is 1,"],"metadata":{"id":"Cx2hRoO6hkMa"}},{"cell_type":"code","source":["sum(predictions[18])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c1avjpMJhaUr","executionInfo":{"status":"ok","timestamp":1668458952738,"user_tz":300,"elapsed":418,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"fddc3622-6c6f-485b-cb4e-2687ba5cd6db"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0000001606792648"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["Using the function 'np.argmax()' we obtain the index corresponding to the maximum probability,"],"metadata":{"id":"Lzl9ib2niNgi"}},{"cell_type":"code","source":["np.argmax(predictions[18])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jcYQ2WhthdO0","executionInfo":{"status":"ok","timestamp":1668458955978,"user_tz":300,"elapsed":194,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"501ad454-8662-46bc-f23f-6eae68d3ba5b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["---\n","##¬†Visualization of the Results\n","\n","In order to visualize the result of the mode, we define two plotting functions. The first one shows the image together with the predicted value. The second one shows the probabilities of all the targets for the given sample."],"metadata":{"id":"aMBGHGNFjTTO"}},{"cell_type":"code","source":["def plot_image(i, p=predictions, tar = test_labels, image = test_images):\n","  target, img = tar[i], image[i]\n","  plt.grid(False)\n","  plt.xticks([])\n","  plt.yticks([])\n","  plt.imshow(img, cmap='gray')\n","\n","  pred_target = np.argmax(p[i])\n","  if pred_target == target:\n","    color = 'blue'\n","  else:\n","    color = 'red'\n","\n","  plt.xlabel(\"Predicted: {} ({:2.0f}%)   True:{}\".format(pred_target,\n","                                100*np.max(p),\n","                                target),\n","                                color=color)\n","\n","def plot_value_array(i, p=predictions, tar = test_labels):\n","  target = tar[i]\n","  #plt.grid(False)\n","  plt.xticks(range(6))\n","  plt.yticks([])\n","  thisplot = plt.bar(range(6), p[i], color=\"#777777\")\n","  plt.ylim([0, 1])\n","  pred_target = np.argmax(p[i])\n","\n","  thisplot[pred_target].set_color('red')\n","  thisplot[target].set_color('blue')"],"metadata":{"id":"jss5fU9gckwb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["i = 413\n","\n","plt.figure(figsize=(10,4))\n","plt.subplot(1,2,1)\n","plot_image(i)\n","plt.subplot(1,2,2)\n","plot_value_array(i)\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":286},"id":"AvmpNylwc0PV","executionInfo":{"status":"ok","timestamp":1668459007844,"user_tz":300,"elapsed":559,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"10f7c00a-d503-44bb-b59a-88099bc0c338"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 720x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":[],"metadata":{"id":"IlLCMLDb5YaT"},"execution_count":null,"outputs":[]}]}