{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mBFEmr745Op"
   },
   "source": [
    "![Astrofisica Computacional](../logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 03. Logistic Regression Algorithm.\n",
    "\n",
    "\n",
    "Eduard Larra√±aga (ealarranaga@unal.edu.co)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5dP3sa345Or"
   },
   "source": [
    "\n",
    "### About this notebook\n",
    "\n",
    "In this worksheet, we implement a Logistic regression algorithm to classify a dataset.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cBGk0qdl45Os"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXadA4FK45Ot"
   },
   "source": [
    "### The data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "executionInfo": {
     "elapsed": 735,
     "status": "ok",
     "timestamp": 1611332892015,
     "user": {
      "displayName": "Eduard Alexis Larranaga",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCVABzEgj-rCdyxWa29RnA0kIYUCXAaVbnRYOEhQ=s64",
      "userId": "04402438389940282602"
     },
     "user_tz": 300
    },
    "id": "X7wLEZjO45Ot",
    "outputId": "c0285da0-d53c-443f-c9d8-c99a186186c7"
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"TitanicData/train_X.csv\", index_col=0)\n",
    "y_train = pd.read_csv(\"TitanicData/train_Y.csv\", index_col=0)\n",
    "X_test = pd.read_csv(\"TitanicData/test_X.csv\", index_col=0)\n",
    "y_test = pd.read_csv(\"TitanicData/test_Y.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "executionInfo": {
     "elapsed": 799,
     "status": "ok",
     "timestamp": 1611335836667,
     "user": {
      "displayName": "Eduard Alexis Larranaga",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCVABzEgj-rCdyxWa29RnA0kIYUCXAaVbnRYOEhQ=s64",
      "userId": "04402438389940282602"
     },
     "user_tz": 300
    },
    "id": "vIYqJQ4E45Ox",
    "outputId": "680343f7-2772-46d1-90d0-69bf67a7307b",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       "Id                                                    \n",
       "0        3    0  22.0      1      0   7.2500         1\n",
       "1        1    1  38.0      1      0  71.2833         0\n",
       "2        3    1  26.0      0      0   7.9250         1\n",
       "3        1    1  35.0      1      0  53.1000         1\n",
       "4        3    0  35.0      0      0   8.0500         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Survived\n",
       "Id          \n",
       "0          0\n",
       "1          1\n",
       "2          1\n",
       "3          1\n",
       "4          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(pd.read_csv(\"TitanicData/train_X.csv\", index_col=0))\n",
    "y_train = np.asarray(pd.read_csv(\"TitanicData/train_Y.csv\", index_col=0))\n",
    "X_test = np.asarray(pd.read_csv(\"TitanicData/test_X.csv\", index_col=0))\n",
    "y_test = np.asarray(pd.read_csv(\"TitanicData/test_Y.csv\", index_col=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train :  (891, 7)\n",
      "Shape of Y_train :  (891, 1)\n",
      "Shape of X_test :  (418, 7)\n",
      "Shape of Y_test :  (418, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train : \", X_train.shape)\n",
    "print(\"Shape of Y_train : \", y_train.shape)\n",
    "print(\"Shape of X_test : \", X_test.shape)\n",
    "print(\"Shape of Y_test : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSGjHxku45Oy"
   },
   "source": [
    "### Logistic Regression\n",
    "\n",
    "\n",
    "For logistic regression (and binary classification) we use a fit function with the form\n",
    "\n",
    "\\begin{equation}\n",
    "y_p (x;W,b) = \\sigma (z(x;W,b)) \n",
    "\\end{equation}\n",
    "\n",
    "where $\\sigma (z)$ represents the sigmoid (logistic) function,\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma (z) = \\frac{1}{1+e^{-z}} \n",
    "\\end{equation}\n",
    "\n",
    "and $z(x;W,b) = Wx + b$. Therefore, we have\n",
    "\n",
    "\\begin{equation}\n",
    "y_p (x;W,b) = \\frac{1}{1+e^{-(Wx + b)}}. \n",
    "\\end{equation}\n",
    "\n",
    "Since the result of the regression will be a binary classification, with values 0 or 1, the cost function cannot have the form\n",
    "\n",
    "\\begin{equation}\n",
    "f_{c} = \\frac{1}{n} \\sum_{i=1}^n \\left( y_{p}(x_i) - y_i \\right)^2.\n",
    "\\end{equation}\n",
    "\n",
    "Instead, we will use a cost function defined as\n",
    "\n",
    "\\begin{equation}\n",
    "f_{c} = - \\frac{1}{n} \\sum_{i=1}^n \\left[ y_i \\log(y_p) + (1-y_i)\\log (1-y_p) \\right].\n",
    "\\end{equation}\n",
    "\n",
    "Note that, from this cost function, we conclude that:\n",
    "\n",
    "- For a sigle sample with target value $y_i = 0$, the cost function reduces to $f_{c} = - \\log (1-y_p)$. Note that a prediction near $y_p \\sim 1$ gives a huge cost, $f_c \\rightarrow \\infty$, while a prediction near $y_p \\sim y_0 = 0$ gives a low cost, $f_c \\rightarrow 0$.\n",
    "\n",
    "- For a sigle sample with target value $y_i = 1$, the cost function reduces to $f_{c} = - \\log (y_p)$. This time, a prediction of $y_p \\sim 0$ gives a huge cost, $f_c \\rightarrow \\infty$, while a prediction of $y_p \\sim y_0 = 1$ gives a low cost, $f_c \\rightarrow 0$.\n",
    "\n",
    "\n",
    "The gradient of the cost function, w.r.t. the parameters $W$ and $b$ give\n",
    "\\begin{align}\n",
    "\\frac{ \\partial f_{c}}{\\partial W} = &- \\frac{1}{n} \\sum_{i=1}^n \\left[ \\frac{y_i}{y_p} \\frac{ \\partial y_p}{\\partial W} - \\frac{1-y_i}{1-y_p} \\frac{ \\partial y_p}{\\partial W} \\right] \\\\ \n",
    "= &- \\frac{1}{n} \\sum_{i=1}^n \\left[ \\frac{y_i}{y_p}  - \\frac{1-y_i}{1-y_p}  \\right]\\left( y_p (1 -y_p) x_i \\right) \\\\\n",
    "= &- \\frac{1}{n} \\sum_{i=1}^n \\left[ y_i(1 -y_p) - (1-y_i) y_p  \\right] x_i\\\\\n",
    "= &- \\frac{1}{n} \\sum_{i=1}^n \\left[ y_i -  y_p  \\right] x_i\\\\\n",
    "= & \\frac{1}{n} \\sum_{i=1}^n \\left[ y_p -  y_i  \\right] x_i.\n",
    "\\end{align}\n",
    "\n",
    "and \n",
    "\n",
    "\\begin{align}\n",
    "\\frac{ \\partial f_{c}}{\\partial b} = &- \\frac{1}{n} \\sum_{i=1}^n \\left[ \\frac{y_i}{y_p} \\frac{ \\partial y_p}{\\partial b} - \\frac{1-y_i}{1-y_p} \\frac{ \\partial y_p}{\\partial b} \\right] \\\\ \n",
    "= &- \\frac{1}{n} \\sum_{i=1}^n \\left[ \\frac{y_i}{y_p}  - \\frac{1-y_i}{1-y_p}  \\right]\\left( y_p (1 -y_p)\\right) \\\\\n",
    "= &- \\frac{1}{n} \\sum_{i=1}^n \\left[ y_i(1 -y_p) - (1-y_i) y_p  \\right] \\\\\n",
    "= &- \\frac{1}{n} \\sum_{i=1}^n \\left[ y_i -  y_p  \\right] \\\\\n",
    "= & \\frac{1}{n} \\sum_{i=1}^n \\left[ y_p -  y_i  \\right].\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    '''\n",
    "    Logistic regression class\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def sigmoid(self, Z):\n",
    "        return 1/(1 + np.exp(-Z))\n",
    "\n",
    "    def Z(self, X):\n",
    "        '''\n",
    "        Function to fit\n",
    "        '''\n",
    "        return self.b + np.dot(X,self.W)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.sigmoid(self.Z(X))\n",
    "    \n",
    "    def cost(self, X, y):\n",
    "        '''\n",
    "        Cost function\n",
    "        '''\n",
    "        Yp = self.predict(X)\n",
    "        return -(1/self.n)*np.sum(y*np.log(Yp) + (1-y)*np.log(1-Yp))\n",
    "    \n",
    "    def grad_cost(self, X,y):\n",
    "        '''\n",
    "        Gradient of the cost function\n",
    "        '''\n",
    "        Yp = self.predict(X)\n",
    "        grad_dW = (1/self.n)*np.dot(X.T, Yp-y)\n",
    "        grad_db = (1/self.n)*np.sum(Yp-y)\n",
    "        return grad_dW, grad_db\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Optimization function\n",
    "        '''\n",
    "        alpha= 0.002  # Learning rate\n",
    "        tol = 1e-13    # Tolerance\n",
    "        np.random.seed(413)\n",
    "        self.m = X.shape[1] # Number of features\n",
    "        self.n = X.shape[0] # Number od samples\n",
    "        \n",
    "        self.W = np.zeros([self.m,1])#np.random.rand(self.m)\n",
    "        self.b = 0#np.random.rand(1)\n",
    "        Y = self.sigmoid(self.Z(X))\n",
    "\n",
    "        self.history = []\n",
    "        self.history.append(self.cost(X, y))\n",
    "        print('Initial cost = ', self.history[0])\n",
    "        \n",
    "        epoch = 0 # Epochs\n",
    "        epsilon = 1\n",
    "        while epsilon>tol and epoch<200000:\n",
    "            # Gradient\n",
    "            grad_dW, grad_db = self.grad_cost(X,y)\n",
    "\n",
    "            self.W = self.W - alpha*grad_dW\n",
    "            self.b = self.b - alpha*grad_db\n",
    "            \n",
    "            self.history.append(self.cost(X, y))\n",
    "            epsilon = abs(self.history[epoch] - self.history[epoch+1])\n",
    "            epoch +=1\n",
    "        \n",
    "        print('Final cost = ', self.history[-1])\n",
    "        print('Number of epochs = ',epoch)\n",
    "    \n",
    "    def accuracy(self, X, y):\n",
    "        Yp = self.predict(X)\n",
    "        Yp = Yp > 0.5\n",
    "        Yp = np.array(Yp, dtype = 'int64')\n",
    "        acc = (1 - np.sum(abs(Yp - y))/len(y))*100\n",
    "        print(\"Accuracy of the model is : \", round(acc, 2), \"%\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial cost =  0.6931471805599454\n",
      "Final cost =  0.44482356011000806\n",
      "Number of epochs =  200000\n",
      "\n",
      "The optimized parameters are\n",
      "W =  [[-0.96633465]\n",
      " [ 2.76276562]\n",
      " [-0.03164378]\n",
      " [-0.33249102]\n",
      " [-0.11435116]\n",
      " [ 0.00343123]\n",
      " [-0.11285891]]\n",
      "b =  1.757999615723724\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "W, b = lr.W, lr.b\n",
    "\n",
    "print('\\nThe optimized parameters are')\n",
    "print('W = ',W)\n",
    "print('b = ',b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is :  90.91 %\n"
     ]
    }
   ],
   "source": [
    "lr.accuracy(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Training history\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(lr.history, color='crimson')\n",
    "#plt.plot(lr.history[0:100], color='crimson')\n",
    "plt.ylabel(r'cost function')\n",
    "plt.xlabel(r'epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "colab": {
   "collapsed_sections": [],
   "name": "LinearFit01.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
