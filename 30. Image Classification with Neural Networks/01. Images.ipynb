{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Astrofisica Computacional](../logo.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5soGuirloNgq"
   },
   "source": [
    "---\n",
    "## 01. Images\n",
    "\n",
    "\n",
    "Eduard LarraÃ±aga (ealarranaga@unal.edu.co)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ff4KTapaoNgx"
   },
   "source": [
    "### Abstract\n",
    "\n",
    "In this notebook we will implement a perceptron algorithm, which incorporates the idea of a linear regression and a activation function to define a classification method.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def genImg():\n",
    "    fuz = 0.5\n",
    "    image_data = np.zeros([28,28])\n",
    "    N = np.random.randint(6)\n",
    "    for i in range(N):\n",
    "        x,y = np.random.randint(28, size=2)\n",
    "        image_data[x,y] = 1\n",
    "        if x-1>=0:\n",
    "            image_data[x-1,y] = np.random.rand()*fuz\n",
    "            if y-1>=0:\n",
    "                image_data[x-1,y-1] = np.random.rand()*fuz\n",
    "                image_data[x,y-1] = np.random.rand()*fuz\n",
    "            if y+1<28:\n",
    "                image_data[x-1,y+1] = np.random.rand()*fuz\n",
    "                image_data[x,y+1] = np.random.rand()*fuz\n",
    "        if x+1<28:\n",
    "            image_data[x+1,y] = np.random.rand()*fuz\n",
    "            if y-1>=0:\n",
    "                image_data[x+1,y-1] = np.random.rand()*fuz\n",
    "            if y+1<28:\n",
    "                image_data[x+1,y+1] = np.random.rand()*fuz\n",
    "    return image_data, N\n",
    "\n",
    "samples = 1000\n",
    "data = np.zeros([samples,28,28])\n",
    "targets = np.zeros(samples, dtype=int)\n",
    "for j in range(samples):\n",
    "    data[j], targets[j] = genImg()\n",
    "\n",
    "np.save(\"data.npy\", data)\n",
    "np.save(\"targets.npy\", targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply this perceptron to many samples to obtain the corresponding results,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "datos = np.load(\"data.npy\")\n",
    "tar = np.load(\"targets.npy\")\n",
    "\n",
    "for i in range(len(tar)):\n",
    "    print(tar[i])\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(datos[i], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "colab": {
   "collapsed_sections": [],
   "name": "01. Decision Trees.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
